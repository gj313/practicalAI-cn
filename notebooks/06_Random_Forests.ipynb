{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOChJSNXtC9g"
   },
   "source": [
    "# 随机森林"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OLIxEDq6VhvZ"
   },
   "source": [
    "<img src=\"../images/logo.png\" width=150>\n",
    "\n",
    "在本节课，我们将探索决策树，并且拓展它到随机森林。这种类型的模型，和我们之前见过的线性和逻辑回归不同，他们没有权重但是有很好的可解释性。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VoMq0eFRvugb"
   },
   "source": [
    "# 概述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qWro5T5qTJJL"
   },
   "source": [
    "<img src=\"../images/dtree.jpg\" width=350>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4Y55tpzIjOa"
   },
   "source": [
    "* **目标:**  给出一些数据，选择特征并且决定以什么样的方式分裂数据来做出预测。\n",
    "* **优点:**\n",
    "  * 决策树可以做成分类树和回归树。\n",
    "  * 具有很强的可解释性.\n",
    "  * 仅需很少的数据预处理。\n",
    "* **缺点:**\n",
    "  * 当训练数据少于分类类别的时候表现很差。\n",
    "* **其他:** 一组决策树可以构成随机森林，预测结果也会由所有的决策树所决定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jq65LZJbSpzd"
   },
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-HBPn8zPTQfZ"
   },
   "source": [
    "我们来看上方的决策树样例，它用来决策外面的天气是否可以在外玩耍。数据有三个特征(weather, humiditiy和wind) 和结果 (yes or no).\n",
    "\n",
    "*步骤*: \n",
    "1.   基于每一个特征进行分割(例如. 根据三个特征来判断结果是yes还是no）\n",
    "2.   计算每个特征分裂时候的损失。一些热门的算法比如使用Gini系数来计算的CART算法，还有使用熵和信息增益来计算的ID3。它们都基本上测量了预测值中的杂质或者无序。详细请见 [blog post](https://medium.com/deep-math-machine-learning-ai/chapter-4-decision-trees-algorithms-b93975f7a1f1) 一个详尽的信息增益计算步骤。\n",
    "\n",
    "  * $ H(X) = \\sum_{c \\in C} -p(c) log_2p(c)$\n",
    "  * where:\n",
    "      * H(X): 数据集X的熵\n",
    "      * C: 类别集合\n",
    "      * p(c): 在c类别中和所有实例的占比\n",
    "      \n",
    "  对于一个二分类任务来说，如果所有的样例在一个类别下都是相同的，那么它的熵值为0，如果仅有一半是正确的，那么它的熵值则为1（也是最差的情况等同于瞎猜）。一旦我们决定了熵值，我们需要计算出信息增益(IG)(比如. 在我们把数据X基于特征F分裂后不确定的样本减少了多少)。\n",
    "  \n",
    "  * $ IG(F, X) = H(S) - \\sum_{t\\in T}p(t)H(t) $\n",
    "  * where:\n",
    "      * IG(F. X): 数据X基于特征F分裂后的信息增益\n",
    "      * H(X): 数据集X的熵\n",
    "      * T: 基于分裂F后的子集\n",
    "      * p(t): 所有实例中t的实例数的比例\n",
    "      * H(t): 子集t的熵\n",
    "      \n",
    " **注意**: 对于回归问题，你可以用标准偏差（standard deviation）来取代信息增益。\n",
    "\n",
    "3.   在所有的特征分裂后，信息增益最高的分裂将作为第一个特征的分裂(也就是决策树的根).\n",
    "4.   基于第一次分裂后，重复上述的步骤在余下的所有特征中。最后，我们将分裂到叶子结点，在叶子结点中大部分样本将会来自同一类。\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdutxKgxP68B"
   },
   "source": [
    "# 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCcckUIsP9rh"
   },
   "source": [
    "我们来加载在第三节课中用到的titanic数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B0w9pCHCP-Ep"
   },
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsktUhbXP_GP"
   },
   "outputs": [],
   "source": [
    "# 参数\n",
    "args = Namespace(\n",
    "    seed=1234,\n",
    "    data_file=\"../data/titanic.csv\",\n",
    "    train_size=0.75,\n",
    "    test_size=0.25,\n",
    "    num_epochs=100,\n",
    "    max_depth=4,\n",
    "    min_samples_leaf=5,\n",
    "    n_estimators=10, # 随机森林中包含的决策树个数\n",
    ")\n",
    "\n",
    "# 设置随即种子来保证实验结果的可重复性。\n",
    "np.random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kgrunrh2P_JO"
   },
   "outputs": [],
   "source": [
    "# # 从GitHub上加载数据到notebook本地驱动\n",
    "# url = \"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/data/titanic.csv\"\n",
    "# response = urllib.request.urlopen(url)\n",
    "# html = response.read()\n",
    "# with open(args.data_file, 'wb') as f:\n",
    "#     f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "3eLPo-27P_L3",
    "outputId": "da93034a-432d-4b89-e1b5-c80d902fd962"
   },
   "outputs": [],
   "source": [
    "# 把CSV文件内容读到DataFrame中\n",
    "df = pd.read_csv(args.data_file, header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k-5Y4zLIoE6s"
   },
   "source": [
    "# Scikit-learn实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ql2YltiMS5Sj"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ChBporrVYZB"
   },
   "outputs": [],
   "source": [
    "# 预处理\n",
    "def preprocess(df):\n",
    "  \n",
    "    # 删除掉含有空值的行\n",
    "    df = df.dropna()\n",
    "\n",
    "    # 删除基于文本的特征 (我们以后的课程将会学习怎么使用它们)\n",
    "    features_to_drop = [\"name\", \"cabin\", \"ticket\"]\n",
    "    df = df.drop(features_to_drop, axis=1)\n",
    "\n",
    "    # pclass, sex, 和 embarked 是类别变量\n",
    "    # 我们将把字符串转化成浮点数，不再是逻辑回归中的编码变量\n",
    "    df['sex'] = df['sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    df[\"embarked\"] = df['embarked'].dropna().map( {'S':0, 'C':1, 'Q':2} ).astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "uvc-WzuvVbUZ",
    "outputId": "86147845-fde0-46d9-e09e-cddee0f71b9b"
   },
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "df = preprocess(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KkOqwUtAQHAr",
    "outputId": "2fcadff6-f2d8-4e72-e9f9-a8c623e84d89"
   },
   "outputs": [],
   "source": [
    "# 划分数据到训练集和测试集\n",
    "mask = np.random.rand(len(df)) < args.train_size\n",
    "train_df = df[mask]\n",
    "test_df = df[~mask]\n",
    "print (\"Train size: {0}, test size: {1}\".format(len(train_df), len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZezmRsSnTcqr"
   },
   "outputs": [],
   "source": [
    "# 分离 X 和 y\n",
    "X_train = train_df.drop([\"survived\"], axis=1)\n",
    "y_train = train_df[\"survived\"]\n",
    "X_test = test_df.drop([\"survived\"], axis=1)\n",
    "y_test = test_df[\"survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZeTRfFhiaO2c"
   },
   "source": [
    "**注意**: 你可以随意改动 max_depth 和 min_samples 来观察决策树表现好坏的变化。\n",
    "我们怎么知道什么时候可以停止分裂？如果我们有一个很多特征的数据集，我们的决策树也会非常大。如果我们一直去分裂，我们终究会导致过拟合。所以这里有一些处理办法可以参考：\n",
    "\n",
    "*  设置在叶子节点中的最少样本个数。\n",
    "*  设置一个最大的深度(也就是从树根到叶子节点的最大距离)。\n",
    "*  通过删除几乎没有信息增益的特征对决策树进行剪枝。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W1MJODStIu8V"
   },
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "dtree = DecisionTreeClassifier(criterion=\"entropy\", random_state=args.seed, \n",
    "                               max_depth=args.max_depth, \n",
    "                               min_samples_leaf=args.min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "DIcmEZWxfBOL",
    "outputId": "a7045ea0-f331-4243-ff8f-24ff022c42bb"
   },
   "outputs": [],
   "source": [
    "# 训练\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_xEuD_lSWVs7"
   },
   "outputs": [],
   "source": [
    "# 预测\n",
    "pred_train = dtree.predict(X_train)\n",
    "pred_test = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IgLm9MImWz8s"
   },
   "source": [
    "# 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dfQX2V_JWksY"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FV7xOm-iWxjc",
    "outputId": "1b80282c-bf11-4200-e453-e628925d144d"
   },
   "outputs": [],
   "source": [
    "# 正确率\n",
    "train_acc = accuracy_score(y_train, pred_train)\n",
    "test_acc = accuracy_score(y_test, pred_test)\n",
    "print (\"train acc: {0:.2f}, test acc: {1:.2f}\".format(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xxOAfpvzWku1",
    "outputId": "d0cdd693-2a73-4d80-a12f-840f10629975"
   },
   "outputs": [],
   "source": [
    "# 计算其他的模型评估指标\n",
    "precision, recall, F1, _ = precision_recall_fscore_support(y_test, pred_test, average=\"binary\")\n",
    "print (\"precision: {0:.2f}. recall: {1:.2f}, F1: {2:.2f}\".format(precision, recall, F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PNxTcGWVoSLB"
   },
   "source": [
    "# 可解释性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xqkUvu0-XxcG"
   },
   "outputs": [],
   "source": [
    "# 安装必要的包\n",
    "!apt-get install graphviz\n",
    "!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0rwIL2_W82m"
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "Oaz6KdZgoOr7",
    "outputId": "30d3a761-d2a5-4670-9e49-606ab4831e57"
   },
   "outputs": [],
   "source": [
    "# 可解释性\n",
    "dot_data = StringIO()\n",
    "export_graphviz(dtree, out_file=dot_data, \n",
    "                feature_names=list(train_df.drop(['survived'], axis=1)), \n",
    "                class_names = ['died', 'survived'],\n",
    "                rounded = True, filled= True, special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png(), width=500, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "tMK_w0Sqa6sE",
    "outputId": "06bdc3c4-9f77-4b5d-baf7-044f31b1578c"
   },
   "outputs": [],
   "source": [
    "# 特征重要性\n",
    "features = list(X_test.columns)\n",
    "importances = dtree.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "num_features = len(importances)\n",
    "\n",
    "# 画出树中的特征重要性\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(num_features), importances[indices], color=\"g\", align=\"center\")\n",
    "plt.xticks(range(num_features), [features[i] for i in indices], rotation='45')\n",
    "plt.xlim([-1, num_features])\n",
    "plt.show()\n",
    "\n",
    "# 打印值\n",
    "for i in indices:\n",
    "    print (\"{0} - {1:.3f}\".format(features[i], importances[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hS_763WyD4_3"
   },
   "source": [
    "# 随机森林"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZ5P_xbMD6eb"
   },
   "source": [
    "随机森林由一组，或者说一个集成的决策树在一起构建。它的意图是，与单个决策树相比，一组不同的树将产生更准确的预测。 但是如果我们在相同的数据下用相同的分裂条件比如说信息增益，那么怎么保证每棵树又是不同的呢？这里的解决方法是随机森林中的不同决策树由不同的数据子集组成，甚至不同的特征阈值。\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/forest.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DUEa6BJ5GHLF"
   },
   "source": [
    "# Scikit-learn 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ogq6dncjeb1U"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nuRnhYKF-qT"
   },
   "outputs": [],
   "source": [
    "# 初始化随机森林\n",
    "forest = RandomForestClassifier(\n",
    "    n_estimators=args.n_estimators, criterion=\"entropy\", \n",
    "    max_depth=args.max_depth, min_samples_leaf=args.min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "iSkEBA4Xe4gY",
    "outputId": "5a5766d7-2faa-4f6e-fc21-c40e86dc4563"
   },
   "outputs": [],
   "source": [
    "# 训练\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8IkBGrQ6fD11"
   },
   "outputs": [],
   "source": [
    "# 预测\n",
    "pred_train = forest.predict(X_train)\n",
    "pred_test = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "EMk8RWRSfD6C",
    "outputId": "54098b2a-6f35-4b76-b407-25cd5807d942"
   },
   "outputs": [],
   "source": [
    "# 正确率\n",
    "train_acc = accuracy_score(y_train, pred_train)\n",
    "test_acc = accuracy_score(y_test, pred_test)\n",
    "print (\"train acc: {0:.2f}, test acc: {1:.2f}\".format(train_acc, test_acc))\n",
    "\n",
    "# 计算其他评估指标 \n",
    "precision, recall, F1, _ = precision_recall_fscore_support(y_test, pred_test, average=\"binary\")\n",
    "print (\"precision: {0:.2f}. recall: {1:.2f}, F1: {2:.2f}\".format(precision, recall, F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gYcrpjEvFEkF"
   },
   "source": [
    "# 可解释性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BtSEnVtYFEmj"
   },
   "source": [
    "检查随机森林正确性并获得特征重要性非常容易。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "4zmqPwuZfD_3",
    "outputId": "024b95e1-a02c-4d22-a1bf-7e6a924e5417"
   },
   "outputs": [],
   "source": [
    "# 特征重要性\n",
    "features = list(X_test.columns)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "num_features = len(importances)\n",
    "\n",
    "# 画出树中的特征重要性\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(num_features), importances[indices], yerr=std[indices], \n",
    "        color=\"g\", align=\"center\")\n",
    "plt.xticks(range(num_features), [features[i] for i in indices], rotation='45')\n",
    "plt.xlim([-1, num_features])\n",
    "plt.show()\n",
    "\n",
    "# 打印\n",
    "for i in indices:\n",
    "    print (\"{0} - {1:.3f}\".format(features[i], importances[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2VCgsSBK9rr"
   },
   "source": [
    "# 网格搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zajR4pDlK9uf"
   },
   "source": [
    "在我们的随机森林中，我们有许多不同的超参数(criterion, max_depth, 等等)甚至在以后的课程中我们会见到很多的模型有更多的超参数。我们怎么知道应该选择什么样的值？我们必须根据它们在验证集上产生的性能来调整它们。Scikit learn提供了详尽的网格搜索功能，以便我们可以调整我们的超参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RMeG5C3gGPg"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PmXiTM8PLKzT"
   },
   "outputs": [],
   "source": [
    "# 创建网格的参数 \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 50],\n",
    "    'max_features': [len(features)],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [4, 8],\n",
    "    'n_estimators': [5, 10, 50] # of trees\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aIhJ4Wupgmvy"
   },
   "outputs": [],
   "source": [
    "# 初始化随机森林\n",
    "forest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cM6AE1Kigmyl"
   },
   "outputs": [],
   "source": [
    "# 实例化网格搜索\n",
    "grid_search = GridSearchCV(estimator=forest, param_grid=param_grid, cv=3, \n",
    "                           n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "NorCjCFSg3uU",
    "outputId": "2c8bd43f-7c28-4847-f72a-b46e6f493306"
   },
   "outputs": [],
   "source": [
    "# 网格搜索拟合数据\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "NLPPr568g3xA",
    "outputId": "83989349-eb37-4988-e5bc-0e4213523209"
   },
   "outputs": [],
   "source": [
    "# 查看最佳参数组合\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "SAA7pZamg3zp",
    "outputId": "08d9fef5-82e2-4cc5-8836-176a59610fed"
   },
   "outputs": [],
   "source": [
    "# 使用最佳参数训练\n",
    "best_forest = grid_search.best_estimator_\n",
    "best_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FfrJFo6TiEBJ"
   },
   "outputs": [],
   "source": [
    "# 预测\n",
    "pred_train = best_forest.predict(X_train)\n",
    "pred_test = best_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1VM5goioiEjQ",
    "outputId": "4d25a809-a8d9-415d-ce82-e701364cfd67"
   },
   "outputs": [],
   "source": [
    "# 正确率\n",
    "train_acc = accuracy_score(y_train, pred_train)\n",
    "test_acc = accuracy_score(y_test, pred_test)\n",
    "print (\"train acc: {0:.2f}, test acc: {1:.2f}\".format(train_acc, test_acc))\n",
    "\n",
    "# 计算其他评价指标\n",
    "precision, recall, F1, _ = precision_recall_fscore_support(y_test, pred_test, average=\"binary\")\n",
    "print (\"precision: {0:.2f}. recall: {1:.2f}, F1: {2:.2f}\".format(precision, recall, F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L0aQUomQoni1"
   },
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iF1iNNhxLIpE"
   },
   "source": [
    "- regression example\n",
    "- gini vs. entropy"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "06_Random_Forests",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
