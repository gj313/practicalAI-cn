{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOChJSNXtC9g"
   },
   "source": [
    "# 数据和模型 Data and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OLIxEDq6VhvZ"
   },
   "source": [
    "<img src=\"../images/logo.png\" width=150>\n",
    "\n",
    "目前为止，我们看到了应对不同任务（回归/分类）而建立在不同数据集上的多种模型，在后续的课程中，我们将继续学习更多算法。但是，我们忽略了一个关于数据和模型的根本问题：质量和数量。简而言之，一个机器学习模型消耗输入数据，产生预测结果。用于训练的数据质量和数量，直接决定了预测的质量。垃圾数据产生垃圾结果。\n",
    "\n",
    "<img src=\"../images/nutshell.png\" width=500>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FLH7kzZl8wnf"
   },
   "source": [
    "# 配置 Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qAE9BjMH8x4q"
   },
   "source": [
    "我们通过具体的代码示例，了解所有的概念。首先，我们人工制造一些训练模型的数据。任务是根据白细胞的数量和血压预测肿瘤是良性还是恶性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m0nzLDcVXJTx"
   },
   "outputs": [],
   "source": [
    "# Load PyTorch library\n",
    "# !pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9uu2nngKDrW"
   },
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import collections\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gPHmsndLdUOH"
   },
   "outputs": [],
   "source": [
    "# Set Numpy and PyTorch seeds\n",
    "def set_seeds(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0-dXQiLlTIgz",
    "outputId": "d525f333-8024-48d3-ab6d-ea9507b9a94a"
   },
   "outputs": [],
   "source": [
    "# Arguments\n",
    "args = Namespace(\n",
    "    seed=1234,\n",
    "    cuda=False,\n",
    "    shuffle=True,\n",
    "    data_file=\"../data/tumors.csv\",\n",
    "    reduced_data_file=\"../data/tumors_reduced.csv\",\n",
    "    train_size=0.75,\n",
    "    test_size=0.25,\n",
    "    num_hidden_units=100,\n",
    "    learning_rate=1e-3,\n",
    "    num_epochs=100,\n",
    ")\n",
    "\n",
    "# Set seeds\n",
    "set_seeds(seed=args.seed, cuda=args.cuda)\n",
    "\n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "print(\"Using CUDA: {}\".format(args.cuda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RV2IddoZde-r"
   },
   "source": [
    "# 数据 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5wDazzQdaoy2"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbsXoFVgdh6K"
   },
   "outputs": [],
   "source": [
    "# # Upload data from GitHub to notebook's local drive\n",
    "# url = \"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/data/tumors.csv\"\n",
    "# response = urllib.request.urlopen(url)\n",
    "# html = response.read()\n",
    "# with open(args.data_file, 'wb') as fp:\n",
    "#     fp.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "y6LNWmoidh8q",
    "outputId": "a2ee99a4-8c89-41d4-d482-7e098b097d14"
   },
   "outputs": [],
   "source": [
    "# Raw data\n",
    "df = pd.read_csv(args.data_file, header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YVo6CuZLC3h2"
   },
   "outputs": [],
   "source": [
    "def plot_tumors(df):\n",
    "    i = 0; colors=['r', 'b']\n",
    "    for name, group in df.groupby(\"tumor\"):\n",
    "        plt.scatter(group.leukocyte_count, group.blood_pressure, edgecolors='k',\n",
    "                   color=colors[i]); i += 1\n",
    "    plt.xlabel('leukocyte count')\n",
    "    plt.ylabel('blood pressure')\n",
    "    plt.legend(['0 - benign', '1 - malignant'], loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "nXFUmnfte6z6",
    "outputId": "2b797875-3e15-4e67-ed8c-1585e9e54ba9"
   },
   "outputs": [],
   "source": [
    "# Plot data\n",
    "plot_tumors(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "237OzHqlNQ-D"
   },
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X = df[['leukocyte_count', 'blood_pressure']].to_numpy()\n",
    "y = df['tumor'].to_numpy()\n",
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y.ravel()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0pahDv9WLD2S",
    "outputId": "e3e7a63a-e027-4d04-8c54-8d658419750d"
   },
   "outputs": [],
   "source": [
    "# 打乱数据 Shuffle data\n",
    "shuffle_indicies = torch.LongTensor(random.sample(range(0, len(X)), len(X)))\n",
    "X = X[shuffle_indicies]\n",
    "y = y[shuffle_indicies]\n",
    "\n",
    "# Split datasets\n",
    "test_start_idx = int(len(X) * args.train_size)\n",
    "X_train = X[:test_start_idx] \n",
    "y_train = y[:test_start_idx] \n",
    "X_test = X[test_start_idx:] \n",
    "y_test = y[test_start_idx:]\n",
    "print(\"We have %i train samples and %i test samples.\" % (len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "owLnzReJJdpj"
   },
   "source": [
    "# 模型 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zlPe1lXEJfcA"
   },
   "source": [
    "基于这个人造数据训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WhYfDOjJdIV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nTtsFHZY_G45"
   },
   "outputs": [],
   "source": [
    "# 多层感知 Multilayer Perceptron \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        a_1 = F.relu(self.fc1(x_in)) # activaton function added!\n",
    "        y_pred = self.fc2(a_1)\n",
    "\n",
    "        if apply_softmax:\n",
    "            y_pred = F.softmax(y_pred, dim=1)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1kXlfHpPJ5Vq"
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = MLP(input_dim=len(df.columns)-1, \n",
    "            hidden_dim=args.num_hidden_units, \n",
    "            output_dim=len(set(df.tumor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ncxbef0yJ6pD"
   },
   "outputs": [],
   "source": [
    "# Optimization\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "srlaBr8oiftE"
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "def get_accuracy(y_pred, y_target):\n",
    "    n_correct = torch.eq(y_pred, y_target).sum().item()\n",
    "    accuracy = n_correct / len(y_pred) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Mjg4u-zCK90q",
    "outputId": "cdcefbe6-fbdf-4cfb-de36-d365573d2ed5"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "for t in range(args.num_epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    # Accuracy\n",
    "    _, predictions = y_pred.max(dim=1)\n",
    "    accuracy = get_accuracy(y_pred=predictions.long(), y_target=y_train)\n",
    "\n",
    "    # Loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    \n",
    "    # Verbose\n",
    "    if t%20==0: \n",
    "        print (\"epoch: {0:02d} | loss: {1:.4f} | accuracy: {2:.1f}%\".format(\n",
    "            t, loss, accuracy))\n",
    "\n",
    "    # Zero all gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wHCvuSEaK-2x"
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "_, pred_train = model(X_train, apply_softmax=True).max(dim=1)\n",
    "_, pred_test = model(X_test, apply_softmax=True).max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5whE6K0rOmGN",
    "outputId": "0d895286-edda-4b8e-f520-ebb63d8fd070"
   },
   "outputs": [],
   "source": [
    "# Train and test accuracies\n",
    "train_acc = get_accuracy(y_pred=pred_train, y_target=y_train)\n",
    "test_acc = get_accuracy(y_pred=pred_test, y_target=y_test)\n",
    "print (\"train acc: {0:.1f}%, test acc: {1:.1f}%\".format(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bzFb90SJOmI2"
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "def plot_multiclass_decision_boundary(model, X, y):\n",
    "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 101), np.linspace(y_min, y_max, 101))\n",
    "    cmap = plt.cm.Spectral\n",
    "    \n",
    "    X_test = torch.from_numpy(np.c_[xx.ravel(), yy.ravel()]).float()\n",
    "    y_pred = model(X_test, apply_softmax=True)\n",
    "    _, y_pred = y_pred.max(dim=1)\n",
    "    y_pred = y_pred.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, y_pred, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ViwfNFOYRDkm"
   },
   "source": [
    "我们将绘制一个白色点，这个点已知是一个恶性肿瘤。我们训练后的模型可以精确的预测它确实是一个恶性肿瘤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "colab_type": "code",
    "id": "_oEf6XRmOsJE",
    "outputId": "34be9806-8b48-4c61-c5df-fe38a29ae6d5"
   },
   "outputs": [],
   "source": [
    "# Visualize the decision boundary\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Train\")\n",
    "plot_multiclass_decision_boundary(model=model, X=X_train, y=y_train)\n",
    "plt.scatter(np.mean(df.leukocyte_count), np.mean(df.blood_pressure), s=200, \n",
    "            c='b', edgecolor='w', linewidth=2)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Test\")\n",
    "plot_multiclass_decision_boundary(model=model, X=X_test, y=y_test)\n",
    "plt.scatter(np.mean(df.leukocyte_count), np.mean(df.blood_pressure), s=200, \n",
    "            c='b', edgecolor='w', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o231eJaQPi5E"
   },
   "source": [
    "完美！我们得到了测试和训练上非常好的表现。我们将用这个数据展示数据质量和数量的重要性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZ3rnGH8PtBu"
   },
   "source": [
    "# 数据质量和数量 Data Quality and Quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ONRP3WQgR3zc"
   },
   "source": [
    "我们去除决策边界附件的一些训练数据，观察模型的鲁棒性如何。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sxd2S63EYtxt"
   },
   "outputs": [],
   "source": [
    "# # Upload data from GitHub to notebook's local drive\n",
    "# url = \"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/data/tumors_reduced.csv\"\n",
    "# response = urllib.request.urlopen(url)\n",
    "# html = response.read()\n",
    "# with open(args.reduced_data_file, 'wb') as fp:\n",
    "#     fp.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "sU69PjH3Z4bm",
    "outputId": "a9d507a7-9f96-4bb2-81ac-35485f8ca5f5"
   },
   "outputs": [],
   "source": [
    "# Raw reduced data\n",
    "df_reduced = pd.read_csv(args.reduced_data_file, header=0)\n",
    "df_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "1OwgEJSsZ4g5",
    "outputId": "5464cb82-b7a7-4cc2-e137-27379e6d5c27"
   },
   "outputs": [],
   "source": [
    "# Plot data\n",
    "plot_tumors(df_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r9xlQme0beTY"
   },
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X = df_reduced[['leukocyte_count', 'blood_pressure']].to_numpy()\n",
    "y = df_reduced['tumor'].to_numpy()\n",
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y.ravel()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RerzDWJQbeVz",
    "outputId": "98b02a78-e164-4f79-9492-054feab9d55b"
   },
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "shuffle_indicies = torch.LongTensor(random.sample(range(0, len(X)), len(X)))\n",
    "X = X[shuffle_indicies]\n",
    "y = y[shuffle_indicies]\n",
    "\n",
    "# Split datasets\n",
    "test_start_idx = int(len(X) * args.train_size)\n",
    "X_train = X[:test_start_idx] \n",
    "y_train = y[:test_start_idx] \n",
    "X_test = X[test_start_idx:] \n",
    "y_test = y[test_start_idx:]\n",
    "print(\"We have %i train samples and %i test samples.\" % (len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JCZ7yDl1OsdU"
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = MLP(input_dim=len(df_reduced.columns)-1, \n",
    "            hidden_dim=args.num_hidden_units, \n",
    "            output_dim=len(set(df_reduced.tumor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-IZ4YOKtSCRk"
   },
   "outputs": [],
   "source": [
    "# Optimization\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "7NBWLKDISDj8",
    "outputId": "83cff604-b034-4aea-e4b3-47a713209b07"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "for t in range(args.num_epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    # Accuracy\n",
    "    _, predictions = y_pred.max(dim=1)\n",
    "    accuracy = get_accuracy(y_pred=predictions.long(), y_target=y_train)\n",
    "\n",
    "    # Loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    \n",
    "    # Verbose\n",
    "    if t%20==0: \n",
    "        print (\"epoch: {0} | loss: {1:.4f} | accuracy: {2:.1f}%\".format(t, loss, accuracy))\n",
    "\n",
    "    # Zero all gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uGWbZlhUSFOz"
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "_, pred_train = model(X_train, apply_softmax=True).max(dim=1)\n",
    "_, pred_test = model(X_test, apply_softmax=True).max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Gz2Sh4JpSFT9",
    "outputId": "8cb4c86b-0ff2-4548-a710-09883a8dc349"
   },
   "outputs": [],
   "source": [
    "# Train and test accuracies\n",
    "train_acc = get_accuracy(y_pred=pred_train, y_target=y_train)\n",
    "test_acc = get_accuracy(y_pred=pred_test, y_target=y_test)\n",
    "print (\"train acc: {0:.1f}%, test acc: {1:.1f}%\".format(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "colab_type": "code",
    "id": "DmTCz8OnSFRn",
    "outputId": "f3cf293c-b22b-49bf-d037-ca021376a5d7"
   },
   "outputs": [],
   "source": [
    "# Visualize the decision boundary\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Train\")\n",
    "plot_multiclass_decision_boundary(model=model, X=X_train, y=y_train)\n",
    "plt.scatter(np.mean(df.leukocyte_count), np.mean(df.blood_pressure), s=200, \n",
    "            c='b', edgecolor='w', linewidth=2)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Test\")\n",
    "plot_multiclass_decision_boundary(model=model, X=X_test, y=y_test)\n",
    "plt.scatter(np.mean(df.leukocyte_count), np.mean(df.blood_pressure), s=200, \n",
    "            c='b', edgecolor='w', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kdP98xnlbvVn"
   },
   "source": [
    "这是一个非常惊人而又现实的情景。基于我们删减的人造数据，我们得到了一个在测试数据上表现非常好的模型。但是，当我们我使用之前相同的白色点（已知是良性肿瘤）进行测试时，预测显示是一个恶性肿瘤。我们完全误判了肿瘤。\n",
    "\n",
    "**模型不是水晶球** \n",
    "在开始机器学习之前，很重要的一点是：我们需要观察我们的数据，并且扪心自问他们是否真实表示了我们将解决的问题。如果开始时的数据质量很差，即使训练很好，并且在测试数据上也很一致，这个模型依然是不可信的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yWzAC39adTwk"
   },
   "source": [
    "# 模型 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cR45QpjQdY6N"
   },
   "source": [
    "一旦你自信地认为你的数据质量和数量都非常好，你可以开始思考模型了。你选择模型的类型取决于很多因素，包括：任务、数据类型、需求复杂度等。\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/models1.png\" width=550>\n",
    "\n",
    "当你一旦搞清楚你的任务需要的模型类型时，从一个简单的模型开始，逐渐增加复杂度。你肯定不想直接从神经网络开始，因为很可能不是你数据和任务的正确模型。平衡模型的复杂度是你数据科学生涯的主要关键任务。**简单模型 → 复杂模型**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "09_Data_and_Models-cn",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
